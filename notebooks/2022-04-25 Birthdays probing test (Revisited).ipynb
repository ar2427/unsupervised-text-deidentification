{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54dd8d98-0748-478b-8c82-6b77cfa44e53",
   "metadata": {},
   "source": [
    "# Birthdays probing test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d252cb9-4ee5-42f2-98df-af6e72555090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jxm3/research/deidentification/unsupervised-deidentification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529344f2-556a-49e3-92e4-b5055c9b0469",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import DocumentProfileMatchingTransformer\n",
    "\n",
    "import os\n",
    "\n",
    "num_cpus = os.cpu_count()\n",
    "\n",
    "model = DocumentProfileMatchingTransformer.load_from_checkpoint(\n",
    "    # distilbert-distilbert model\n",
    "    #    '/home/jxm3/research/deidentification/unsupervised-deidentification/saves/distilbert-base-uncased__dropout_0.8_0.8/deid-wikibio_default/1irhznnp_130/checkpoints/epoch=25-step=118376.ckpt',\n",
    "    # roberta-distilbert model\n",
    "    # '/home/jxm3/research/deidentification/unsupervised-deidentification/saves/roberta__distilbert-base-uncased__dropout_0.8_0.8/deid-wikibio_default/1f7mlhxn_162/checkpoints/epoch=16-step=309551.ckpt',\n",
    "    # roberta-distilbert model trained for longer\n",
    "    '/home/jxm3/research/deidentification/unsupervised-deidentification/saves/roberta__distilbert-base-uncased__dropout_0.8_0.8/deid-wikibio_default/3nbt75gp_171/checkpoints/epoch=20-step=382387.ckpt',\n",
    "    document_model_name_or_path='roberta-base',\n",
    "    profile_model_name_or_path='distilbert-base-uncased',\n",
    "    num_workers=min(8, num_cpus),\n",
    "    train_batch_size=64,\n",
    "    eval_batch_size=64,\n",
    "    learning_rate=1e-6,\n",
    "    max_seq_length=256,\n",
    "    pretrained_profile_encoder=False,\n",
    "    word_dropout_ratio=0.0,\n",
    "    word_dropout_perc=0.0,\n",
    "    lr_scheduler_factor=0.5,\n",
    "    lr_scheduler_patience=3,\n",
    "    adversarial_mask_k_tokens=0,\n",
    "    train_without_names=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "29132408-7f12-472e-896b-494b99fda702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing WikipediaDataModule with num_workers = 8 and mask token `<mask>`\n",
      "loading wiki_bio[1.2.0] split train[:100%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset wiki_bio (/home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading wiki_bio[1.2.0] split val[:20%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset wiki_bio (/home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da)\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-58e5e96e220311ed.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-778e9a6d1b0dfab7.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-3c4e94260fbd4dd3.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-9e279afc7bfb46f2.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-7c5ac0e6f364c103.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-02418e1d9ade71ab.arrow\n"
     ]
    }
   ],
   "source": [
    "from dataloader import WikipediaDataModule\n",
    "import os\n",
    "\n",
    "num_cpus = os.cpu_count()\n",
    "\n",
    "dm = WikipediaDataModule(\n",
    "    mask_token=model.document_tokenizer.mask_token,\n",
    "    dataset_name='wiki_bio',\n",
    "    dataset_train_split='train[:100%]',\n",
    "    dataset_val_split='val[:20%]',\n",
    "    dataset_version='1.2.0',\n",
    "    num_workers=min(8, num_cpus),\n",
    "    train_batch_size=64,\n",
    "    eval_batch_size=64,\n",
    ")\n",
    "dm.setup(\"fit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ea5280-96de-48cd-9ccc-23d8c3f3237d",
   "metadata": {},
   "source": [
    "## Get the birthday data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "774c9b7c-aedb-4ea6-9635-4c9ddd5c0639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "d = datetime.datetime.strptime('17 january 1943', \"%d %B %Y\")\n",
    "d.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d2c6da6f-9788-4a13-bb05-46383951d49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "\n",
    "def process_dataset(_dataset) -> List[Tuple[int, int]]:\n",
    "    _processed_data = []\n",
    "    for idx, d in enumerate(tqdm(_dataset, 'processing birthdays')):\n",
    "        profile = d['profile']\n",
    "        date_str_matches = re.search(r\"birth_date \\| ([\\d]{1,4} [a-z]+ [\\d]{1,4})\", profile)\n",
    "        if date_str_matches:\n",
    "            date_str = date_str_matches.group(1)\n",
    "            # print(date_str)\n",
    "            # parse to datetime.datetime\n",
    "            try:\n",
    "                dt = datetime.datetime.strptime(date_str, \"%d %B %Y\")\n",
    "            except ValueError as e:\n",
    "                # print(e)\n",
    "                continue\n",
    "            day_class_num = (dt.month - 1) * 31 + (dt.day - 1)\n",
    "            _processed_data.append((idx, day_class_num))\n",
    "    return _processed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f793a8c-de55-4c12-8dd2-c3e6fa1f9e60",
   "metadata": {},
   "source": [
    "## Create birthday data module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ce4eaea4-daf0-4996-96c9-0826a537b835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a816a73ea9741ef92815f1bfdf42f4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processing birthdays:   0%|          | 0/14566 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pytorch_lightning import LightningDataModule\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_cpus = os.cpu_count()\n",
    "\n",
    "class BirthdayDataModule(LightningDataModule):\n",
    "    train_dataset: List[Tuple[int, int]]\n",
    "    val_dataset: List[Tuple[int, int]]\n",
    "    batch_size: int\n",
    "    def __init__(self, dm: WikipediaDataModule, batch_size: int = 64):\n",
    "        super().__init__()\n",
    "        self.train_dataset = process_dataset(dm.train_dataset)\n",
    "        self.val_dataset = process_dataset(dm.val_dataset)\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = min(4, num_cpus)\n",
    "\n",
    "    def setup(self, stage: str) -> None:\n",
    "        return\n",
    "\n",
    "    def train_dataloader(self) -> process_dataset(dm.val_dataset):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=False # Only shuffle for train\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=False\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "13aa79a4-cced-4f94-a39b-1534759fd5ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbe53e6e1d474d5880564a75e60907b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processing birthdays:   0%|          | 0/582659 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "380970870c674f3da09b5335ffb3318d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processing birthdays:   0%|          | 0/14566 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "birthday_dm = BirthdayDataModule(dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2982e8b-786a-4e7e-a0c8-957ecbef6e29",
   "metadata": {},
   "source": [
    "## Create birthday model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1057c57f-21af-4795-953b-68ab3a829427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing profile embeddings before first epoch...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/2] Precomputing train embeddings - profile:   0%|          | 0/9105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[2/2] Precomputing val embeddings - profile:   0%|          | 0/228 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def precompute_embeddings(model: DocumentProfileMatchingTransformer, datamodule: WikipediaDataModule):\n",
    "    model.profile_model.cuda()\n",
    "    model.profile_model.eval()\n",
    "    print('Precomputing profile embeddings before first epoch...')\n",
    "    \n",
    "    model.train_profile_embeddings = np.zeros((len(datamodule.train_dataset), model.profile_embedding_dim))\n",
    "    for train_batch in tqdm(datamodule.train_dataloader(), desc=\"[1/2] Precomputing train embeddings - profile\", colour=\"cyan\", leave=False):\n",
    "        with torch.no_grad():\n",
    "            profile_embeddings = model.forward_profile_text(text=train_batch[\"profile\"])\n",
    "        model.train_profile_embeddings[train_batch[\"text_key_id\"]] = profile_embeddings.cpu()\n",
    "    model.train_profile_embeddings = torch.tensor(model.train_profile_embeddings, dtype=torch.float32)\n",
    "    \n",
    "    model.val_profile_embeddings = np.zeros((len(datamodule.val_dataset), model.profile_embedding_dim))\n",
    "    for val_batch in tqdm(datamodule.val_dataloader(), desc=\"[2/2] Precomputing val embeddings - profile\", colour=\"green\", leave=False):\n",
    "        with torch.no_grad():\n",
    "            profile_embeddings = model.forward_profile_text(text=val_batch[\"profile\"])\n",
    "        model.val_profile_embeddings[val_batch[\"text_key_id\"]] = profile_embeddings.cpu()\n",
    "    model.val_profile_embeddings = torch.tensor(model.val_profile_embeddings, dtype=torch.float32)\n",
    "    \n",
    "    \n",
    "    model.profile_model.train()\n",
    "\n",
    "precompute_embeddings(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "07850e58-4195-4b64-bc1c-899d3df4820b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "import torch\n",
    "import torchmetrics\n",
    "import transformers\n",
    "\n",
    "from pytorch_lightning import LightningModule\n",
    "from transformers import AdamW\n",
    "\n",
    "class BirthdayModel(LightningModule):\n",
    "    \"\"\"Probes the PROFILE for birthday info.\"\"\"\n",
    "    profile_embeddings: torch.Tensor\n",
    "    classifier: torch.nn.Module\n",
    "    learning_rate: float\n",
    "    \n",
    "    def __init__(self, model: DocumentProfileMatchingTransformer, learning_rate: float):\n",
    "        super().__init__()\n",
    "        # We can pre-calculate these embeddings bc\n",
    "        self.train_profile_embeddings = torch.tensor(model.train_profile_embeddings.cpu())\n",
    "        self.val_profile_embeddings = torch.tensor(model.val_profile_embeddings.cpu())\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            torch.nn.Linear(model.profile_embedding_dim, 64),\n",
    "            torch.nn.Dropout(p=0.01),\n",
    "            # 12 * 31 possible outputs\n",
    "            torch.nn.Linear(64, 12*31),\n",
    "        )\n",
    "        self.learning_rate = learning_rate\n",
    "        self.train_accuracy = torchmetrics.Accuracy()\n",
    "        self.val_accuracy   = torchmetrics.Accuracy()\n",
    "        self.loss_criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def training_step(self, batch: Tuple[int, int], batch_idx: int) -> torch.Tensor:\n",
    "        profile_idxs, birthday_idxs = batch\n",
    "        assert ((0 <= profile_idxs) & (birthday_idxs < len(self.train_profile_embeddings))).all()\n",
    "        assert ((0 <= birthday_idxs) & (birthday_idxs < 12*31)).all()\n",
    "        # print('profile_idxs, birthday_idxs =', profile_idxs, birthday_idxs)\n",
    "        clf_device = next(self.classifier.parameters()).device\n",
    "        with torch.no_grad():\n",
    "            embedding = self.train_profile_embeddings[profile_idxs].to(clf_device)\n",
    "        birthday_logits = self.classifier(embedding)\n",
    "        # loss = torch.nn.functional.cross_entropy(\n",
    "        #     birthday_logits, birthday_idxs\n",
    "        # )\n",
    "        # if batch_idx == 0: breakpoint()\n",
    "        self.log('train_accuracy', self.train_accuracy(birthday_logits, birthday_idxs))\n",
    "        if batch_idx % 300 == 0: print('train accuracy:', self.train_accuracy(birthday_logits, birthday_idxs))\n",
    "        return self.loss_criterion(birthday_logits, birthday_idxs)\n",
    "    \n",
    "    def validation_step(self, batch: Dict[str, torch.Tensor], batch_idx: int):\n",
    "        profile_idxs, birthday_idxs = batch\n",
    "        assert ((0 <= profile_idxs) & (profile_idxs < len(self.val_profile_embeddings))).all()\n",
    "        assert ((0 <= birthday_idxs) & (birthday_idxs < 12*31)).all()\n",
    "        # print('profile_idxs, birthday_idxs =', profile_idxs, birthday_idxs)\n",
    "        clf_device = next(self.classifier.parameters()).device\n",
    "        with torch.no_grad():\n",
    "            embedding = self.val_profile_embeddings[profile_idxs].to(clf_device)\n",
    "        # print('emebdding.shape:', embedding.shape)\n",
    "        birthday_logits = self.classifier(embedding)\n",
    "        # print('birthday_logits.shape:', birthday_logits.shape)\n",
    "        loss = torch.nn.functional.cross_entropy(\n",
    "            birthday_logits, birthday_idxs\n",
    "        )\n",
    "        if batch_idx == 0: self.log('val_accuracy', self.val_accuracy(birthday_logits, birthday_idxs))\n",
    "        return self.loss_criterion(birthday_logits, birthday_idxs)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Prepare optimizer and schedule (linear warmup and decay)\"\"\"\n",
    "        optimizer = AdamW(\n",
    "            list(self.classifier.parameters()), lr=self.learning_rate\n",
    "        )\n",
    "        return optimizer\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e8da2e-b0c4-417e-8a39-34e2b20fdbb4",
   "metadata": {},
   "source": [
    "## Train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "99ae16d1-a388-4352-8e46-ef86bc8232ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer, seed_everything\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "num_validations_per_epoch = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f9ca3e84-33e7-4cde-a4ad-a12334cbcb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-152-a10e39455c4f>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.train_profile_embeddings = torch.tensor(model.train_profile_embeddings.cpu())\n",
      "<ipython-input-152-a10e39455c4f>:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.val_profile_embeddings = torch.tensor(model.val_profile_embeddings.cpu())\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "birthday_model = BirthdayModel(model, 1e-3)\n",
    "birthday_dm.batch_size = 512\n",
    "\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "trainer = Trainer(\n",
    "    default_root_dir=f\"saves/jup/birthday_probing\",\n",
    "    val_check_interval=1.0,\n",
    "    max_epochs=25,\n",
    "    log_every_n_steps=50,\n",
    "    gpus=torch.cuda.device_count(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "3ad30bce-e533-47d8-9cd0-756bd000973d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Set SLURM handle signals.\n",
      "\n",
      "  | Name           | Type             | Params\n",
      "----------------------------------------------------\n",
      "0 | classifier     | Sequential       | 73.4 K\n",
      "1 | train_accuracy | Accuracy         | 0     \n",
      "2 | val_accuracy   | Accuracy         | 0     \n",
      "3 | loss_criterion | CrossEntropyLoss | 0     \n",
      "----------------------------------------------------\n",
      "73.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "73.4 K    Total params\n",
      "0.294     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccb862eb139e4ecbba2894408728e261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: tensor(0.0039, device='cuda:0')\n",
      "train accuracy: tensor(0., device='cuda:0')\n",
      "train accuracy: tensor(0.0098, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: tensor(0.0039, device='cuda:0')\n",
      "train accuracy: tensor(0., device='cuda:0')\n",
      "train accuracy: tensor(0.0078, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: tensor(0.0039, device='cuda:0')\n",
      "train accuracy: tensor(0.0039, device='cuda:0')\n",
      "train accuracy: tensor(0.0039, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: tensor(0.0020, device='cuda:0')\n",
      "train accuracy: tensor(0.0020, device='cuda:0')\n",
      "train accuracy: tensor(0.0039, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: tensor(0.0020, device='cuda:0')\n",
      "train accuracy: tensor(0.0059, device='cuda:0')\n",
      "train accuracy: tensor(0.0039, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: tensor(0.0039, device='cuda:0')\n",
      "train accuracy: tensor(0.0020, device='cuda:0')\n",
      "train accuracy: tensor(0.0039, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: tensor(0., device='cuda:0')\n",
      "train accuracy: tensor(0.0039, device='cuda:0')\n",
      "train accuracy: tensor(0.0078, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: tensor(0., device='cuda:0')\n",
      "train accuracy: tensor(0.0039, device='cuda:0')\n",
      "train accuracy: tensor(0.0059, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: tensor(0., device='cuda:0')\n",
      "train accuracy: tensor(0.0039, device='cuda:0')\n",
      "train accuracy: tensor(0.0039, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: tensor(0.0059, device='cuda:0')\n",
      "train accuracy: tensor(0.0039, device='cuda:0')\n",
      "train accuracy: tensor(0.0059, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: tensor(0., device='cuda:0')\n",
      "train accuracy: tensor(0.0039, device='cuda:0')\n",
      "train accuracy: tensor(0.0039, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: tensor(0., device='cuda:0')\n",
      "train accuracy: tensor(0.0020, device='cuda:0')\n",
      "train accuracy: tensor(0.0039, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: tensor(0., device='cuda:0')\n",
      "train accuracy: tensor(0.0020, device='cuda:0')\n",
      "train accuracy: tensor(0.0039, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: tensor(0., device='cuda:0')\n",
      "train accuracy: tensor(0.0020, device='cuda:0')\n",
      "train accuracy: tensor(0.0059, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: tensor(0.0039, device='cuda:0')\n",
      "train accuracy: tensor(0.0059, device='cuda:0')\n",
      "train accuracy: tensor(0.0039, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: tensor(0.0020, device='cuda:0')\n",
      "train accuracy: tensor(0.0078, device='cuda:0')\n",
      "train accuracy: tensor(0.0078, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: tensor(0.0020, device='cuda:0')\n",
      "train accuracy: tensor(0.0039, device='cuda:0')\n",
      "train accuracy: tensor(0.0059, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d059dd59953442fa63ba47e0a74f9bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _releaseLock at 0x7f30890a0700>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jxm3/.conda/envs/textattack/lib/python3.9/logging/__init__.py\", line 227, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 4176418, 4176442, 4176466, 4176490, 4176514, 4176538, 4176562) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/textattack/lib/python3.9/site-packages/torch/utils/data/dataloader.py:990\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 990\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    991\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[0;32m~/.conda/envs/textattack/lib/python3.9/multiprocessing/queues.py:114\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll(timeout):\n\u001b[0;32m--> 114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [155]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbirthday_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbirthday_dm\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/textattack/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:740\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, train_dataloader, ckpt_path)\u001b[0m\n\u001b[1;32m    735\u001b[0m     rank_zero_deprecation(\n\u001b[1;32m    736\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`trainer.fit(train_dataloader)` is deprecated in v1.4 and will be removed in v1.6.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    737\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Use `trainer.fit(train_dataloaders)` instead. HINT: added \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    738\u001b[0m     )\n\u001b[1;32m    739\u001b[0m     train_dataloaders \u001b[38;5;241m=\u001b[39m train_dataloader\n\u001b[0;32m--> 740\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    741\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/textattack/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:685\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;124;03mError handling, intended to be used only for main trainer function entry points (fit, validate, test, predict)\u001b[39;00m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;124;03mas all errors should funnel through them\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;124;03m    **kwargs: keyword arguments to be passed to `trainer_fn`\u001b[39;00m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 685\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;66;03m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[39;00m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n",
      "File \u001b[0;32m~/.conda/envs/textattack/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:777\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;66;03m# TODO: ckpt_path only in v1.7\u001b[39;00m\n\u001b[1;32m    776\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m ckpt_path \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_from_checkpoint\n\u001b[0;32m--> 777\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    780\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/textattack/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1199\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint_connector\u001b[38;5;241m.\u001b[39mresume_end()\n\u001b[1;32m   1198\u001b[0m \u001b[38;5;66;03m# dispatch `start_training` or `start_evaluating` or `start_predicting`\u001b[39;00m\n\u001b[0;32m-> 1199\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;66;03m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[39;00m\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_dispatch()\n",
      "File \u001b[0;32m~/.conda/envs/textattack/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1279\u001b[0m, in \u001b[0;36mTrainer._dispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_type_plugin\u001b[38;5;241m.\u001b[39mstart_predicting(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1279\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_type_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_training\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/textattack/lib/python3.9/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py:202\u001b[0m, in \u001b[0;36mTrainingTypePlugin.start_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstart_training\u001b[39m(\u001b[38;5;28mself\u001b[39m, trainer: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.Trainer\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# double dispatch to initiate the training loop\u001b[39;00m\n\u001b[0;32m--> 202\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_results \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/textattack/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1289\u001b[0m, in \u001b[0;36mTrainer.run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting:\n\u001b[1;32m   1288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_predict()\n\u001b[0;32m-> 1289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/textattack/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1319\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1317\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m   1318\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1319\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/textattack/lib/python3.9/site-packages/pytorch_lightning/loops/base.py:145\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 145\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/textattack/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py:234\u001b[0m, in \u001b[0;36mFitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    231\u001b[0m data_fetcher \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39m_data_connector\u001b[38;5;241m.\u001b[39mget_profiled_dataloader(dataloader)\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;66;03m# the global step is manually decreased here due to backwards compatibility with existing loggers\u001b[39;00m\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;66;03m# as they expect that the same step is used when logging epoch end metrics even when the batch loop has\u001b[39;00m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;66;03m# finished. this means the attribute does not exactly track the number of optimizer steps applied.\u001b[39;00m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# TODO(@carmocca): deprecate and rename so users don't get confused\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/textattack/lib/python3.9/site-packages/pytorch_lightning/loops/base.py:146\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_advance_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/textattack/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py:242\u001b[0m, in \u001b[0;36mTrainingEpochLoop.on_advance_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_check_val:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mvalidating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 242\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;66;03m# -----------------------------------------\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m# SAVE LOGGERS (ie: Tensorboard, etc...)\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;66;03m# -----------------------------------------\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/textattack/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py:337\u001b[0m, in \u001b[0;36mTrainingEpochLoop._run_validation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_loop\u001b[38;5;241m.\u001b[39m_reload_evaluation_dataloaders()\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 337\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/textattack/lib/python3.9/site-packages/pytorch_lightning/loops/base.py:145\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 145\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/textattack/lib/python3.9/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py:110\u001b[0m, in \u001b[0;36mEvaluationLoop.advance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_fetcher \u001b[38;5;241m=\u001b[39m dataloader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39m_data_connector\u001b[38;5;241m.\u001b[39mget_profiled_dataloader(\n\u001b[1;32m    106\u001b[0m     dataloader, dataloader_idx\u001b[38;5;241m=\u001b[39mdataloader_idx\n\u001b[1;32m    107\u001b[0m )\n\u001b[1;32m    108\u001b[0m dl_max_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_batches[dataloader_idx]\n\u001b[0;32m--> 110\u001b[0m dl_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl_max_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_dataloaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# store batch level output per dataloader\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs\u001b[38;5;241m.\u001b[39mappend(dl_outputs)\n",
      "File \u001b[0;32m~/.conda/envs/textattack/lib/python3.9/site-packages/pytorch_lightning/loops/base.py:140\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_skip()\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m--> 140\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_run_start\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/textattack/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py:86\u001b[0m, in \u001b[0;36mEvaluationEpochLoop.on_run_start\u001b[0;34m(self, data_fetcher, dataloader_idx, dl_max_batches, num_dataloaders)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;241m=\u001b[39m data_fetcher\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reload_dataloader_state_dict(data_fetcher)\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[43m_update_dataloader_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_progress\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mready\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/textattack/lib/python3.9/site-packages/pytorch_lightning/loops/utilities.py:121\u001b[0m, in \u001b[0;36m_update_dataloader_iter\u001b[0;34m(data_fetcher, batch_idx)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;124;03m\"\"\"Attach the dataloader.\"\"\"\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_fetcher, DataLoaderIterDataFetcher):\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# restore iteration\u001b[39;00m\n\u001b[0;32m--> 121\u001b[0m     dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    123\u001b[0m     dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(data_fetcher)\n",
      "File \u001b[0;32m~/.conda/envs/textattack/lib/python3.9/site-packages/pytorch_lightning/utilities/fetching.py:199\u001b[0m, in \u001b[0;36mAbstractDataFetcher.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader)\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_patch()\n\u001b[0;32m--> 199\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprefetching\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprefetch_batches\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/textattack/lib/python3.9/site-packages/pytorch_lightning/utilities/fetching.py:258\u001b[0m, in \u001b[0;36mDataFetcher.prefetching\u001b[0;34m(self, prefetch_batches)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(prefetch_batches):\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 258\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fetch_next_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/textattack/lib/python3.9/site-packages/pytorch_lightning/utilities/fetching.py:300\u001b[0m, in \u001b[0;36mDataFetcher._fetch_next_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    298\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_fetch_start()\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_profiler(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfetch_next_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 300\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfetched \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_fetch_end(batch, data)\n",
      "File \u001b[0;32m~/.conda/envs/textattack/lib/python3.9/site-packages/torch/utils/data/dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 521\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.conda/envs/textattack/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1186\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1185\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1186\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1189\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/textattack/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1152\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1152\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1153\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1154\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.conda/envs/textattack/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1003\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1002\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[0;32m-> 1003\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(pids_str)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[1;32m   1005\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 4176418, 4176442, 4176466, 4176490, 4176514, 4176538, 4176562) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "trainer.fit(birthday_model, birthday_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "04ee97b0-bae0-4da5-a3b8-37c7a907a2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ab25fb93-cb9e-4e9a-a240-82bb354a5e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emebdding.shape: torch.Size([64, 768])\n",
      "birthday_logits.shape: torch.Size([64, 372])\n",
      "loss: tensor(6.0617, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "val_batch = next(iter(birthday_dm.val_dataloader()))\n",
    "\n",
    "def do_validation_batch(batch, batch_idx):\n",
    "    profile_idxs, birthday_idxs = batch\n",
    "    clf_device = next(birthday_model.classifier.parameters()).device\n",
    "    embedding = birthday_model.val_profile_embeddings[profile_idxs].to(clf_device)\n",
    "    print('emebdding.shape:', embedding.shape)\n",
    "    birthday_logits = birthday_model.classifier(embedding)\n",
    "    print('birthday_logits.shape:', birthday_logits.shape)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        birthday_logits, birthday_idxs\n",
    "    )\n",
    "    # self.log('val_accuracy', self.val_accuracy(birthday_logits, birthday_idxs))\n",
    "    print('loss:', loss)\n",
    "\n",
    "do_validation_batch(val_batch, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c4109e40-b072-4cc9-990b-ed8ea0b7801a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 18, 19, 20, 21, 23,\n",
       "         26, 28, 30, 31, 32, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 47, 48, 49,\n",
       "         50, 51, 52, 53, 54, 55, 56, 60, 61, 62, 63, 67, 68, 69, 70, 71, 72, 73,\n",
       "         74, 76, 77, 78, 79, 80, 81, 82, 83, 85]),\n",
       " tensor([339,  75,  93, 131, 221, 331, 329, 334, 106, 241, 102, 219, 282, 129,\n",
       "         206, 211,  14, 117, 170, 151, 101, 222, 232, 312, 347, 254,  36, 361,\n",
       "          47, 207, 250, 212,  85, 272, 266, 204,  94,   4, 148, 141, 267, 325,\n",
       "          87, 228, 371,  74, 285, 193,  48, 209, 126,  16,  21, 365, 183,  25,\n",
       "         317, 247,  66,  74,  39,  58, 251,  55])]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_batch # last element: idx 85, birthday 55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "39966a7e-07e2-4656-bbdc-c9e990927b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'document': \"ben wilson (born 25 february 1977) is a former australian rules footballer who played with collingwood and the sydney swans in the australian football league (afl) .\\nwilson was secured by collingwood from norwood in the 1994 afl draft with the ninth selection , but first not from a tac cup side .\\nthe south australian did n't feature in the 1995 afl season and then appeared twice for collingwood in 1996 .\\nhe was traded to sydney at the end of 1996 , along with mark orchard and two draft picks , for which collingwood received anthony rocca .\\nhe played in the opening three rounds of the 1997 season but made only one further appearance .\\n\",\n",
       " 'profile': \"fullname | ben wilson\\nname | ben wilson\\noriginalteam | norwood\\nyears | 1996 1997 '' ` total - '' '\\ndraftpick | 9th , 1994 afl draft\\nclubs | collingwood sydney swans\\nbirth_date | 25 february 1977\\narticle_title | ben wilson -lrb- australian footballer -rrb-\\nheightweight | 191 ; kg & nbsp ; cm / 87 & nbsp\\nstatsend | 1997\",\n",
       " 'profile_without_name': \"fullname | ben wilson\\noriginalteam | norwood\\nyears | 1996 1997 '' ` total - '' '\\ndraftpick | 9th , 1994 afl draft\\nclubs | collingwood sydney swans\\nbirth_date | 25 february 1977\\nheightweight | 191 ; kg & nbsp ; cm / 87 & nbsp\\nstatsend | 1997\",\n",
       " 'document_redact_lexical': '<mask> <mask> (born <mask> <mask> <mask>) is a former <mask> rules <mask> who played with <mask> and the <mask> <mask> in the <mask> football league (<mask>) .\\n<mask> was secured by <mask> from <mask> in the <mask> <mask> <mask> with the ninth selection <mask> but first not from a tac cup side .\\nthe south <mask> did n<mask>t feature in the 1995 <mask> season and then appeared twice for <mask> in <mask> .\\nhe was traded to <mask> at the end of <mask> <mask> along with mark orchard and two <mask> picks <mask> for which <mask> received anthony rocca .\\nhe played in the opening three rounds of the <mask> season but made only one further appearance .\\n',\n",
       " 'document_redact_ner': \"<mask> <mask> (born <mask> <mask> <mask>) is a former <mask> rules footballer who played with collingwood and the sydney swans in the <mask> football league (afl) .\\n<mask> was secured by <mask> from norwood in the <mask> afl draft with the <mask> selection , but <mask> not from a tac cup side .\\nthe south <mask> did n't feature in the 1995 afl season and then appeared twice for collingwood in <mask> .\\nhe was traded to sydney at <mask> <mask> <mask> <mask> , along with mark orchard and <mask> draft picks , for which <mask> received <mask> <mask> .\\nhe played in the opening <mask> rounds of the 1997 season but made <mask> <mask> further appearance .\\n\",\n",
       " 'text_key_id': 85}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "55 % 31 # february 24th\n",
    "\n",
    "dm.val_dataset[85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "cab00193-3ebf-4e66-9a56-dcac1efffd25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0936,  0.3824,  0.6874,  0.7990, -0.5991])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "birthday_model.val_profile_embeddings[85][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fa29c237-a9d7-4b3a-9e15-46e4a164e9ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0936,  0.3824,  0.6874,  0.7990, -0.5991], device='cuda:0',\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "model.forward_profile_text(text=[dm.val_dataset[85]['profile']])[0, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9add825b-edad-46ba-8f55-0c9a54715782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batch = next(iter(birthday_dm.train_dataloader()))\n",
    "train_batch # 682, 78\n",
    "78 % 31 # 16 -> this is march 17th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a190c107-567b-4994-a35f-1b3691200206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nationalgoals | 12\\nfullname | jesús candelas rodrigo\\nmanagerclubs | netherlands assistant -rrb- iran netherlands malta thailand -lrb- assistant -rrb- hong kong malaysia netherlands -lrb-\\nname | victor hermans\\narticle_title | victor hermans\\nnationalyears | 1977 -- 1989\\nposition | manager -lrb- association football -rrb-\\ncurrentclub | thailand national futsal team -lrb- head coach -rrb-\\nclubs | mvv maastricht k.s.k. tongeren\\nnationalteam | netherlands -lrb- futsal -rrb-\\nbirth_place | maastricht , netherlands\\nbirth_date | 17 march 1953\\nnationalcaps | 50\\nmanageryears | 1990 2000 2001 2001-2007 2009 -- 2011 2012 -- -- 1992 1992 -- 1996 1996 1997 --\\nheight | 1.72'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.train_dataset[682]['profile']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9ed50693-d79b-41c3-8b4b-5e95a5b28822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3974,  0.4090,  0.3919,  1.2626, -0.1960])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "birthday_model.train_profile_embeddings[682][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b09f9a55-3d33-414d-83c1-743be75183fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3974,  0.4090,  0.3919,  1.2626, -0.1960], device='cuda:0',\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "model.forward_profile_text(text=[dm.train_dataset[682]['profile']])[0, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "54081f5a-d022-41b6-b342-d15ebc793b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0123,  0.0198, -0.0286,  ...,  0.0052, -0.0202,  0.0360],\n",
       "          [-0.0107,  0.0232,  0.0180,  ...,  0.0116, -0.0154, -0.0274],\n",
       "          [-0.0222, -0.0221,  0.0122,  ...,  0.0234,  0.0198,  0.0023],\n",
       "          ...,\n",
       "          [ 0.0127,  0.0177, -0.0266,  ..., -0.0159, -0.0071,  0.0111],\n",
       "          [-0.0245,  0.0075,  0.0298,  ..., -0.0179, -0.0173,  0.0030],\n",
       "          [ 0.0115,  0.0255,  0.0330,  ..., -0.0075, -0.0049, -0.0297]],\n",
       "         device='cuda:0', requires_grad=True)),\n",
       " ('0.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0013,  0.0079,  0.0005, -0.0231,  0.0133, -0.0023,  0.0213, -0.0355,\n",
       "          -0.0328, -0.0144, -0.0042,  0.0066, -0.0263, -0.0157,  0.0100,  0.0275,\n",
       "           0.0136, -0.0305, -0.0026, -0.0168,  0.0358, -0.0242,  0.0104,  0.0301,\n",
       "           0.0180,  0.0171,  0.0291,  0.0126,  0.0347,  0.0225,  0.0016, -0.0308,\n",
       "           0.0349, -0.0179, -0.0320,  0.0195, -0.0254,  0.0104,  0.0150, -0.0162,\n",
       "           0.0283, -0.0039, -0.0328, -0.0060, -0.0165, -0.0120, -0.0170, -0.0235,\n",
       "          -0.0352,  0.0144, -0.0301, -0.0137,  0.0017,  0.0382,  0.0244, -0.0185,\n",
       "           0.0283, -0.0119,  0.0005, -0.0137,  0.0091,  0.0157, -0.0030,  0.0207],\n",
       "         device='cuda:0', requires_grad=True)),\n",
       " ('2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0337, -0.0920,  0.0875,  ..., -0.0636, -0.0773, -0.0574],\n",
       "          [-0.0012,  0.0175, -0.0539,  ...,  0.0705, -0.0700, -0.1099],\n",
       "          [ 0.0043,  0.0764,  0.1039,  ...,  0.0481, -0.0374,  0.0520],\n",
       "          ...,\n",
       "          [-0.0468,  0.0516, -0.0190,  ...,  0.0290,  0.0435,  0.0048],\n",
       "          [ 0.0811,  0.0976,  0.1089,  ...,  0.0472,  0.0555, -0.0006],\n",
       "          [ 0.1114,  0.0204, -0.0691,  ..., -0.0351,  0.0810,  0.0931]],\n",
       "         device='cuda:0', requires_grad=True)),\n",
       " ('2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0870,  0.0729, -0.0289, -0.0677, -0.1012, -0.0503, -0.1068, -0.0736,\n",
       "          -0.0143, -0.0717,  0.1077,  0.1260,  0.0432,  0.0496,  0.0426,  0.0949,\n",
       "          -0.0696,  0.0289,  0.0497, -0.0227, -0.0836,  0.1024,  0.0082,  0.0697,\n",
       "           0.1041,  0.0171, -0.0586,  0.0934, -0.0383,  0.0688,  0.0113,  0.0479,\n",
       "          -0.0159,  0.0595,  0.0331,  0.0836,  0.0340,  0.0831, -0.0236,  0.0065,\n",
       "          -0.0666,  0.0432,  0.1012,  0.0874, -0.0021,  0.0061,  0.1215, -0.0815,\n",
       "          -0.1043, -0.1065,  0.0998, -0.0668, -0.0047, -0.0433,  0.1000,  0.0227,\n",
       "           0.0069, -0.0552, -0.0885, -0.0664, -0.0543, -0.0206,  0.0647,  0.0276,\n",
       "          -0.0650, -0.0591,  0.0337, -0.0533, -0.1014,  0.0148, -0.1074,  0.0308,\n",
       "          -0.0283, -0.0592, -0.0138,  0.0201, -0.0741,  0.1059,  0.0424, -0.0520,\n",
       "           0.0312, -0.0373,  0.1128, -0.0843, -0.0305,  0.0604,  0.1067, -0.0756,\n",
       "          -0.0319, -0.0095,  0.0547, -0.0938,  0.0381, -0.0927, -0.0105, -0.0383,\n",
       "          -0.0553,  0.0072, -0.0008, -0.0551,  0.0037, -0.0960,  0.0292,  0.0733,\n",
       "          -0.0770, -0.0393,  0.0506,  0.0515, -0.0379,  0.0058,  0.0905, -0.1010,\n",
       "           0.0301, -0.0783, -0.0690, -0.0564, -0.0969, -0.0117,  0.0309,  0.0514,\n",
       "           0.0855, -0.0640, -0.1065,  0.0596, -0.0990, -0.1059,  0.1231, -0.0824,\n",
       "          -0.1071,  0.0441,  0.0796, -0.1159,  0.1165,  0.0653,  0.0500,  0.0850,\n",
       "          -0.1092, -0.1192,  0.1046,  0.0314, -0.0910,  0.0083, -0.0866, -0.0979,\n",
       "          -0.0468, -0.0417, -0.0700,  0.1078, -0.0765,  0.1205, -0.1118, -0.0391,\n",
       "           0.0744,  0.0143,  0.0579, -0.0214, -0.0187,  0.0729, -0.1145,  0.0646,\n",
       "           0.0203, -0.0803,  0.0310,  0.0142,  0.0529, -0.1170, -0.0574, -0.0777,\n",
       "           0.0722,  0.1140,  0.0138,  0.0686,  0.0280,  0.0759,  0.0291,  0.0638,\n",
       "          -0.0835, -0.0931, -0.0023, -0.0523,  0.0399,  0.1182,  0.0241,  0.0227,\n",
       "           0.0461, -0.0870, -0.0151,  0.1126,  0.0321,  0.1166,  0.0236,  0.0940,\n",
       "           0.1077, -0.0153, -0.1018,  0.1101,  0.0903, -0.0384,  0.0784,  0.0968,\n",
       "          -0.0963,  0.1054, -0.0868,  0.0435, -0.0348,  0.1197, -0.0928,  0.0439,\n",
       "          -0.0535,  0.1018, -0.0820,  0.0969, -0.0435, -0.0491,  0.0295,  0.0219,\n",
       "          -0.1105, -0.0891,  0.0638,  0.0108,  0.0004, -0.0958,  0.0603,  0.0995,\n",
       "           0.0916, -0.0900, -0.0864,  0.0795, -0.0619, -0.1045,  0.1262, -0.0020,\n",
       "          -0.0095, -0.0310,  0.1080,  0.1055, -0.0381, -0.0963,  0.0451, -0.0762,\n",
       "           0.0488, -0.1098,  0.0326,  0.0781, -0.1216,  0.1130,  0.0296,  0.0486,\n",
       "           0.0601,  0.0250, -0.0084, -0.0991, -0.0696,  0.0300,  0.1073,  0.1068,\n",
       "          -0.0739, -0.0928,  0.0370,  0.0423,  0.0324,  0.0262, -0.1137, -0.0627,\n",
       "           0.1169,  0.0193,  0.0189, -0.0620, -0.0192,  0.1051,  0.0163,  0.0367,\n",
       "          -0.0548,  0.0488,  0.0557,  0.0543, -0.0147,  0.0607,  0.0415,  0.0175,\n",
       "           0.0685, -0.0815, -0.0398,  0.0738,  0.0428,  0.0353,  0.0300,  0.1131,\n",
       "          -0.1003,  0.0438, -0.0313,  0.1084,  0.0659, -0.0906,  0.0310,  0.0552,\n",
       "           0.0548, -0.0414, -0.0009,  0.0893, -0.0711,  0.0315, -0.0204, -0.0999,\n",
       "           0.1099,  0.0822, -0.0023, -0.0762,  0.0335,  0.0416,  0.0140, -0.0180,\n",
       "          -0.0040,  0.0926, -0.0071,  0.0358,  0.0071, -0.0459,  0.0902,  0.0263,\n",
       "          -0.0395, -0.0252, -0.0707,  0.0845, -0.0741, -0.0770,  0.0208,  0.1066,\n",
       "           0.0664, -0.0090,  0.0465,  0.0395, -0.0772,  0.0421,  0.0837,  0.0723,\n",
       "           0.0209,  0.0426,  0.0318, -0.0349,  0.0747, -0.0111, -0.0689,  0.0749,\n",
       "          -0.0526,  0.0575,  0.0819,  0.0539,  0.0136,  0.0303, -0.0580,  0.0291,\n",
       "          -0.0238,  0.0401,  0.0906,  0.0128, -0.0979, -0.0738, -0.0750, -0.0478,\n",
       "          -0.0342,  0.0235, -0.0975, -0.0043, -0.0867, -0.0494,  0.0917,  0.0062,\n",
       "           0.0014, -0.0199, -0.1200, -0.1088], device='cuda:0',\n",
       "         requires_grad=True))]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(birthday_model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3929e3d8-5928-4038-8fd1-b14457c4228a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
