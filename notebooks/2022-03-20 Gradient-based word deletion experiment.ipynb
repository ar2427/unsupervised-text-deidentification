{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54dd8d98-0748-478b-8c82-6b77cfa44e53",
   "metadata": {},
   "source": [
    "# Gradient-based word deletion\n",
    "\n",
    "I trained a model to \"reidentify\" individuals from information about them. Specifically, this model tries to read the beginning of a Wikipedia page and predict (given the infoboxes of many people's Wikipedia page) which person the page is about. Now I'm going to try and fool this \"reidentifier\" model, and see how many words I have to delete in order to fool the reidentifier a certain percentage of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476a8aa4-1973-48e9-842f-dc95dd66c3d4",
   "metadata": {},
   "source": [
    "## 1. Load the model and make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d252cb9-4ee5-42f2-98df-af6e72555090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jxm3/research/deidentification/unsupervised-deidentification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68a87966-0c59-45f7-8502-5e7da6710a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "no precomputed similarities at folder precomputed_similarities/wiki_bio__train[:10%]__2048",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DocumentProfileMatchingTransformer\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mDocumentProfileMatchingTransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwiki_bio\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdistilbert-base-uncased\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexact\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_neighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/research/deidentification/unsupervised-deidentification/model.py:68\u001b[0m, in \u001b[0;36mDocumentProfileMatchingTransformer.__init__\u001b[0;34m(self, model_name_or_path, dataset_name, loss_fn, learning_rate, adam_epsilon, warmup_steps, weight_decay, train_batch_size, eval_batch_size, num_neighbors, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m train_split \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain[:10\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m# TODO: argparse for split/dataset?\u001b[39;00m\n\u001b[1;32m     67\u001b[0m train_save_folder \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecomputed_similarities\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m__\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_split\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m__\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(train_save_folder), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno precomputed similarities at folder \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_save_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     69\u001b[0m train_neighbors_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(train_save_folder, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneighbors.p\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_neighbors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(pickle\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(train_neighbors_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n",
      "\u001b[0;31mAssertionError\u001b[0m: no precomputed similarities at folder precomputed_similarities/wiki_bio__train[:10%]__2048"
     ]
    }
   ],
   "source": [
    "from model import DocumentProfileMatchingTransformer\n",
    "\n",
    "model = DocumentProfileMatchingTransformer(\n",
    "    dataset_name='wiki_bio',\n",
    "    model_name_or_path='distilbert-base-uncased',\n",
    "    num_workers=1,\n",
    "    loss_fn='exact',\n",
    "    num_neighbors=2048\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf32511-1971-482b-88b3-6848e6c83f5f",
   "metadata": {},
   "source": [
    "## 2. Define attack in TextAttack \n",
    "### (a) Gradient-based word deletion\n",
    "### (b) \"Attack success\" as fullfilment of the metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d259f78c-2ece-4727-87e6-b7cb714e5afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (2) code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abde44f-912e-4f31-8abd-8706ce99bbc6",
   "metadata": {},
   "source": [
    "## 3. Run attack for multiple values of $\\epsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93071875-f139-4841-8c47-cc14a327f6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (3) code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
